{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value and Policy Iteration \n",
    "\n",
    "- [x] Small Gridworld (lecture 3)\n",
    "- [x] Teleportation (lecture 1)\n",
    "- [ ] Jack's Car Rental (lecture 3)\n",
    "\n",
    "## Case 1: Small Gridworld\n",
    "Need to go to top-left or bottom right. Each move costs 1 point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.      -13.99976 -19.99964 -21.9996 ]\n",
      " [-13.99976 -17.99968 -19.99964 -19.99964]\n",
      " [-19.99964 -19.99964 -17.99968 -13.99976]\n",
      " [-21.9996  -19.99964 -13.99976   0.     ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=1)\n",
    "\n",
    "grid_size = 4\n",
    "terminal_states = [(0,0), (grid_size-1, grid_size-1)]\n",
    "\n",
    "gamma = 1\n",
    "reward = -1\n",
    "\n",
    "values = np.zeros((grid_size, grid_size))\n",
    "policy = 0.25 * np.ones((grid_size, grid_size, 4))  # LRUD\n",
    "\n",
    "for k in range(200):\n",
    "    new_values = np.zeros_like(values)\n",
    "\n",
    "    # Value Update\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if (i, j) in terminal_states:\n",
    "                new_values[i, j] = 0.\n",
    "                continue\n",
    "\n",
    "            for action, (i_new, j_new) in enumerate([(i-1,j), (i+1,j), (i,j-1), (i,j+1)]):\n",
    "                if i_new < 0 or i_new >= grid_size or j_new < 0 or j_new >= grid_size:\n",
    "                    i_new, j_new = i, j\n",
    "                \n",
    "                returns = values[i_new, j_new]\n",
    "                new_values[i, j] += policy[i, j, action] * (reward + gamma * returns)\n",
    "\n",
    "    values = new_values\n",
    "\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1.  0.]]\n",
      "[[ 0. -1. -2. -2.]\n",
      " [-1. -2. -2. -2.]\n",
      " [-2. -2. -2. -1.]\n",
      " [-2. -2. -1.  0.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "\n",
    "values = np.zeros((grid_size, grid_size))\n",
    "policy = 0.25 * np.ones((grid_size, grid_size, 4))  # LRUD\n",
    "\n",
    "for k in range(5):\n",
    "    print(values)\n",
    "    \n",
    "    new_values = np.zeros_like(values)\n",
    "\n",
    "    # Value Update\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if (i, j) in terminal_states:\n",
    "                new_values[i, j] = 0.\n",
    "                continue\n",
    "\n",
    "            for action, (i_new, j_new) in enumerate([(i-1,j), (i+1,j), (i,j-1), (i,j+1)]):\n",
    "                if i_new < 0 or i_new >= grid_size or j_new < 0 or j_new >= grid_size:\n",
    "                    i_new, j_new = i, j\n",
    "                \n",
    "                returns = values[i_new, j_new]\n",
    "                new_values[i, j] += policy[i, j, action] * (reward + gamma * returns)\n",
    "\n",
    "    values = new_values\n",
    "    # continue\n",
    "\n",
    "    # break\n",
    "\n",
    "    # Policy Update\n",
    "    new_policy = np.zeros_like(policy)\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if (i, j) in terminal_states:\n",
    "                new_policy[i, j] = 0.0\n",
    "                continue\n",
    "            \n",
    "            next_values = np.zeros(4)\n",
    "            for action, (i_new, j_new) in enumerate([(i-1,j), (i+1,j), (i,j-1), (i,j+1)]):\n",
    "                if i_new < 0 or i_new >= grid_size or j_new < 0 or j_new >= grid_size:\n",
    "                    next_values[action] = -np.inf\n",
    "                    continue\n",
    "\n",
    "                next_values[action] = values[i_new, j_new]\n",
    "\n",
    "            best_actions = np.where(next_values == next_values.max())[0]\n",
    "            for a in best_actions:\n",
    "                new_policy[i, j, a] = 1/len(best_actions)\n",
    "\n",
    "    policy = new_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value iteration needs a lot less time when policy is greedily updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Teleportation!"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png) \\\n",
    "Reward at each step = 0 \\\n",
    "Reward for hitting the wall = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "[[ 3.3  8.8  4.4  5.3  1.5]\n",
      " [ 1.5  3.   2.3  1.9  0.5]\n",
      " [ 0.1  0.7  0.7  0.4 -0.4]\n",
      " [-1.  -0.4 -0.4 -0.6 -1.2]\n",
      " [-1.9 -1.3 -1.2 -1.4 -2. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=1)\n",
    "\n",
    "grid_size = 5\n",
    "\n",
    "special_states = [(1,0), (3,0)]\n",
    "\n",
    "special_jumps = {\n",
    "    (1,0): (1, grid_size-1),\n",
    "    (3,0): (3, 2)\n",
    "}\n",
    "\n",
    "special_rewards = {\n",
    "    (1,0): 10,\n",
    "    (3,0): 5\n",
    "}\n",
    "\n",
    "gamma = 0.9\n",
    "\n",
    "values = np.zeros((grid_size, grid_size))\n",
    "policy = 0.25 * np.ones((grid_size, grid_size, 4))  # LRUD\n",
    "\n",
    "for x, y in special_states:\n",
    "    values[x, y] = special_rewards[(x, y)]\n",
    "\n",
    "for k in range(500):\n",
    "    # print('-'*10, f'k = {k}', '-'*10)\n",
    "    # print(values.T)\n",
    "\n",
    "    new_values = np.zeros_like(values)\n",
    "\n",
    "    # Value Update\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if (i, j) in special_states:\n",
    "                new_values[i, j] = special_rewards[(i,j)] + gamma * values[special_jumps[(i,j)]]\n",
    "                continue\n",
    "\n",
    "            for action, (i_new, j_new) in enumerate([(i-1,j), (i+1,j), (i,j-1), (i,j+1)]):\n",
    "                if (i_new < 0 or i_new >= grid_size or j_new < 0 or j_new >= grid_size):\n",
    "                    returns = values[i, j]\n",
    "                    reward = -1\n",
    "                else:\n",
    "                    returns = values[i_new, j_new]\n",
    "                    reward = 0\n",
    "                    # if (i_new, j_new) in special_states:\n",
    "                    #     reward = special_rewards[i_new, j_new]\n",
    "\n",
    "                new_values[i, j] += policy[i, j, action] * (reward + gamma * returns)\n",
    "\n",
    "    mse = np.mean((new_values - values)**2)\n",
    "    # print(f'MSE = {mse}')\n",
    "    if mse < 1e-12:\n",
    "        break\n",
    "\n",
    "\n",
    "    values = new_values\n",
    "\n",
    "print(k)\n",
    "print(values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "[[22.  24.4 22.  19.4 17.5]\n",
      " [19.8 22.  19.8 17.8 16. ]\n",
      " [17.8 19.8 17.8 16.  14.4]\n",
      " [16.  17.8 16.  14.4 13. ]\n",
      " [14.4 16.  14.4 13.  11.7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=1)\n",
    "\n",
    "grid_size = 5\n",
    "\n",
    "special_states = [(1,0), (3,0)]\n",
    "\n",
    "special_jumps = {\n",
    "    (1,0): (1, grid_size-1),\n",
    "    (3,0): (3, 2)\n",
    "}\n",
    "\n",
    "special_rewards = {\n",
    "    (1,0): 10,\n",
    "    (3,0): 5\n",
    "}\n",
    "\n",
    "gamma = 0.9\n",
    "\n",
    "values = np.zeros((grid_size, grid_size))\n",
    "policy = 0.25 * np.ones((grid_size, grid_size, 4))  # LRUD\n",
    "\n",
    "for x, y in special_states:\n",
    "    values[x, y] = special_rewards[(x, y)]\n",
    "\n",
    "for k in range(500):\n",
    "    # print('-'*10, f'k = {k}', '-'*10)\n",
    "    # print(values.T)\n",
    "\n",
    "    new_values = np.zeros_like(values)\n",
    "\n",
    "    # Value Update\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if (i, j) in special_states:\n",
    "                new_values[i, j] = special_rewards[(i,j)] + gamma * values[special_jumps[(i,j)]]\n",
    "                continue\n",
    "\n",
    "            for action, (i_new, j_new) in enumerate([(i-1,j), (i+1,j), (i,j-1), (i,j+1)]):\n",
    "                if (i_new < 0 or i_new >= grid_size or j_new < 0 or j_new >= grid_size):\n",
    "                    returns = values[i, j]\n",
    "                    reward = -1\n",
    "                else:\n",
    "                    returns = values[i_new, j_new]\n",
    "                    reward = 0\n",
    "                    # if (i_new, j_new) in special_states:\n",
    "                    #     reward = special_rewards[i_new, j_new]\n",
    "\n",
    "                new_values[i, j] += policy[i, j, action] * (reward + gamma * returns)\n",
    "\n",
    "    mse = np.mean((new_values - values)**2)\n",
    "    # print(f'MSE = {mse}')\n",
    "    if mse < 1e-12:\n",
    "        break\n",
    "\n",
    "\n",
    "    values = new_values\n",
    "\n",
    "    # Policy Update\n",
    "    new_policy = np.zeros_like(policy)\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if (i, j) in special_states:\n",
    "                new_policy[i, j] = 0.0\n",
    "                continue\n",
    "            \n",
    "            next_values = np.zeros(4)\n",
    "            for action, (i_new, j_new) in enumerate([(i-1,j), (i+1,j), (i,j-1), (i,j+1)]):\n",
    "                if i_new < 0 or i_new >= grid_size or j_new < 0 or j_new >= grid_size:\n",
    "                    next_values[action] = -np.inf\n",
    "                    continue\n",
    "\n",
    "                next_values[action] = values[i_new, j_new]\n",
    "\n",
    "            best_actions = np.where(next_values == next_values.max())[0]\n",
    "            new_policy[i, j, best_actions] = 1\n",
    "            new_policy[i, j] /= new_policy[i, j].sum()\n",
    "\n",
    "    policy = new_policy\n",
    "\n",
    "print(k)\n",
    "print(values.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
